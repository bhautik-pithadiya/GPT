{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pd.read_csv('./data/dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ˜ž...\\n Review of Tenet : This movie could have set a benchmark like matrix and change the movies like it did forever, but unfortunately its a hot mess, hard to follow/keep up. Granted it pushes your minds limits but not like matrix, which you could understand even watching it once (maybe not all of it but still) Tenet, you need to study it to understand it, and that makes me bored. Unlike matrix it looses its charm once you see it or as soon as you figure out the twist, and i dont have the desire to see it again. Whereas the more you watch matrix the more you want to watch it again.\\n Review of Tenet : I watched Tenet...And then, finally, I watched Tenet with subtitles, because it\\'s on Netflix, thinking I would enjoy it more...I did not.Sure, I had better access to the exposition, which is fine, but the grander plot was no more sensible than when I first watched, Sam\\'s subtitles.In brief, Tenet is far less clever than it imagines itself.Time travel is complicated, certainly, proven by the fact that we haven\\'t yet accomplished it. The best time travel movies establish their loose rules, then dance to Chuck Berry tunes, because time travel logic can never adhere to itself. Back To The Future and Avengers: Endgame succeed despite their failures. That is, \"Let\\'s get on with the rest of the plot, because this time travel thing is never going to stand up to scrutiny.\"Tenet is a film that has no other plot'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA['length'] = DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DATA,VAL_DATA = train_test_split(DATA,test_size=0.3,shuffle=True, random_state=42)\n",
    "TRAIN_DATA.reset_index(inplace=True,drop=True)\n",
    "VAL_DATA.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shooting a movie is not easy, and nobody can p...</td>\n",
       "      <td>a movie is not easy, and nobody can probably g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is undoubtedly the superhero movie the film-go...</td>\n",
       "      <td>undoubtedly the superhero movie the film-goer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just how impressed I am. 'Following' is fantas...</td>\n",
       "      <td>how impressed I am. 'Following' is fantastic!S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would rather have seen it at. You'll understan...</td>\n",
       "      <td>rather have seen it at. You'll understand when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>idea what the story was about, and what the ch...</td>\n",
       "      <td>what the story was about, and what the charact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  \\\n",
       "0  shooting a movie is not easy, and nobody can p...   \n",
       "1  is undoubtedly the superhero movie the film-go...   \n",
       "2  just how impressed I am. 'Following' is fantas...   \n",
       "3  would rather have seen it at. You'll understan...   \n",
       "4  idea what the story was about, and what the ch...   \n",
       "\n",
       "                                                   y  \n",
       "0  a movie is not easy, and nobody can probably g...  \n",
       "1  undoubtedly the superhero movie the film-goer ...  \n",
       "2  how impressed I am. 'Following' is fantastic!S...  \n",
       "3  rather have seen it at. You'll understand when...  \n",
       "4  what the story was about, and what the charact...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer.gpt import GptTokenizer\n",
    "tokenizer = GptTokenizer()\n",
    "tokenizer.load('./tokenizer/models/gpt.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split,counter,batch_size):\n",
    "    \n",
    "    data = TRAIN_DATA if split == 'train' else VAL_DATA\n",
    "    X = torch.tensor([tokenizer.encode(data['X'].iloc[i]) for i in range(counter,counter+batch_size)])\n",
    "    Y = torch.tensor([tokenizer.encode(data['y'].iloc[i]) for i in range(counter,counter+batch_size)])\n",
    "    \n",
    "    # x = torch.stack(X)\n",
    "    # y = torch.stack(Y)\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 298 at dim 1 (got 323)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     X,y \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(split, counter, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_batch\u001b[39m(split,counter,batch_size):\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m TRAIN_DATA \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m VAL_DATA\n\u001b[0;32m----> 4\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcounter\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([tokenizer\u001b[38;5;241m.\u001b[39mencode(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(counter,counter\u001b[38;5;241m+\u001b[39mbatch_size)])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# x = torch.stack(X)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# y = torch.stack(Y)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 298 at dim 1 (got 323)"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "batch_size = 5\n",
    "split = 'train'\n",
    "for i in range(5):\n",
    "    X,y = get_batch(split,counter,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
