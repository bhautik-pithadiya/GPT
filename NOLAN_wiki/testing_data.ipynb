{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       X  \\\n",
      "19932  [83, 2246, 115, 2412, 2412, 3855, 76, 378, 744...   \n",
      "19933  [10, 2412, 3855, 76, 378, 744, 266, 1446, 44, ...   \n",
      "19934  [10, 3855, 76, 378, 744, 266, 1446, 44, 3370, ...   \n",
      "19935  [5588, 76, 378, 744, 266, 1446, 44, 3370, 9610...   \n",
      "19936  [68, 744, 266, 1446, 44, 3370, 9610, 662, 1317...   \n",
      "...                                                  ...   \n",
      "30502  [261, 294, 109, 4378, 7318, 403, 111, 264, 482...   \n",
      "30503  [2105, 111, 264, 4828, 5278, 7260, 111, 1221, ...   \n",
      "30504  [111, 4828, 5278, 7260, 111, 1221, 397, 354, 9...   \n",
      "30505  [109, 412, 5278, 7260, 111, 1221, 397, 354, 97...   \n",
      "30506  [288, 103, 5789, 111, 1221, 397, 354, 97, 265,...   \n",
      "\n",
      "                                                       y  \n",
      "19932  [10, 2412, 3855, 76, 378, 744, 266, 1446, 44, ...  \n",
      "19933  [10, 3855, 76, 378, 744, 266, 1446, 44, 3370, ...  \n",
      "19934  [5588, 76, 378, 744, 266, 1446, 44, 3370, 9610...  \n",
      "19935  [68, 744, 266, 1446, 44, 3370, 9610, 662, 1317...  \n",
      "19936  [70, 2934, 9610, 662, 1317, 44, 7714, 2221, 29...  \n",
      "...                                                  ...  \n",
      "30502  [2105, 111, 264, 4828, 5278, 7260, 111, 1221, ...  \n",
      "30503  [111, 4828, 5278, 7260, 111, 1221, 397, 354, 9...  \n",
      "30504  [109, 412, 5278, 7260, 111, 1221, 397, 354, 97...  \n",
      "30505  [288, 103, 5789, 111, 1221, 397, 354, 97, 265,...  \n",
      "30506  [7734, 397, 354, 97, 265, 2131, 620, 111, 46, ...  \n",
      "\n",
      "[213 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the tokenized data\n",
    "data = pd.read_csv('../data/tokenized_data_v3.csv', sep='|')\n",
    "\n",
    "# Parse the JSON strings to lists\n",
    "data['X'] = data['X'].apply(json.loads)\n",
    "data['y'] = data['y'].apply(json.loads)\n",
    "\n",
    "# Find rows where the lengths of X and y are not equal\n",
    "unequal_length_rows = data[data.apply(lambda row: len(row['X']) >256, axis=1)]\n",
    "\n",
    "# Display the rows with unequal lengths\n",
    "print(unequal_length_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [X, y]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.apply(lambda row: len(row['X']) >512, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows after parsing:\n",
      "                                                   X  \\\n",
      "0  [5758, 410, 2412, 551, 962, 1056, 2412, 2412, ...   \n",
      "1  [3519, 2412, 551, 962, 1056, 2412, 2412, 706, ...   \n",
      "2  [10, 551, 962, 1056, 2412, 2412, 706, 8114, 41...   \n",
      "3  [69, 962, 1056, 2412, 2412, 706, 8114, 410, 33...   \n",
      "4  [108, 1280, 2412, 2412, 706, 8114, 410, 331, 7...   \n",
      "\n",
      "                                                   y  \n",
      "0  [3519, 2412, 551, 962, 1056, 2412, 2412, 706, ...  \n",
      "1  [10, 551, 962, 1056, 2412, 2412, 706, 8114, 41...  \n",
      "2  [69, 962, 1056, 2412, 2412, 706, 8114, 410, 33...  \n",
      "3  [108, 1280, 2412, 2412, 706, 8114, 410, 331, 7...  \n",
      "4  [10, 2412, 706, 8114, 410, 331, 7013, 325, 32,...  \n",
      "Rows with unequal lengths:\n",
      "Empty DataFrame\n",
      "Columns: [X, y]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print the first few rows to verify the parsing``\n",
    "print(\"First few rows after parsing:\")\n",
    "print(data.head())\n",
    "\n",
    "# Find rows where the lengths of X and y are not equal\n",
    "def check_unequal_lengths(row):\n",
    "    len_x = len(row['X'])\n",
    "    len_y = len(row['y'])\n",
    "    if len_x != len_y:\n",
    "        print(f\"Unequal lengths found: X={len_x}, y={len_y}, row_index={row.name}\")\n",
    "    return len_x != len_y\n",
    "\n",
    "unequal_length_rows = data[data.apply(check_unequal_lengths, axis=1)]\n",
    "\n",
    "# Display the rows with unequal lengths\n",
    "print(\"Rows with unequal lengths:\")\n",
    "print(unequal_length_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, max_length):\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]\n",
    "        input_ids = text['X']\n",
    "        target_ids = text['y']\n",
    "        \n",
    "        input_ids_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
    "        target_ids_tensor = torch.tensor(target_ids, dtype=torch.long)\n",
    "\n",
    "        return input_ids_tensor, target_ids_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "special_tokens = {'<eos>': 10000, '<pad>': 10001}\n",
    "def collate_fn(batch):\n",
    "    # Separate the input and target sequences\n",
    "    input_ids, target_ids = zip(*batch)\n",
    "    \n",
    "    # Pad the sequences\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=special_tokens['<pad>'])\n",
    "    target_ids_padded = pad_sequence(target_ids, batch_first=True, padding_value=special_tokens['<pad>'])\n",
    "    \n",
    "    return input_ids_padded, target_ids_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize tokenizer and other necessary parameters\n",
    "# tokenizer = ...  # Initialize your tokenizer\n",
    "special_tokens = {'<pad>': 10001, '<eos>': 10000}\n",
    "max_length = 50\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = CustomDataset(data, max_length)\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "# Debugging within DataLoader loop\n",
    "for batch in dataloader:\n",
    "    input_ids, target_ids = batch\n",
    "    if input_ids.shape != target_ids.shape:\n",
    "        print(\"Input IDs shape:\", input_ids.shape)\n",
    "        print(\"Target IDs shape:\", target_ids.shape)\n",
    "        print(\"First batch of Input IDs:\", input_ids[0])\n",
    "        print(\"First batch of Target IDs:\", target_ids[0])\n",
    "        # break  # Only checking the first batch for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
